#网络爬虫的限制
1、来源审查：判断来访HTTP协议头的User-Agent域进行限制
2、发布公告：Robots协议（建议，但不存在约束性）

#Robots协议：告诉爬虫哪些可以抓取哪些不可以
#形式：在网站根目录底下放置robots.txt文件
